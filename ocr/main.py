from paddleocr import PaddleOCR
import cv2
import numpy as np
import re
import json
import os
from typing import Dict, List


class EnglishEssayGrader:
    def __init__(self):
        # ä½¿ç”¨æ–°ç‰ˆPaddleOCRåˆå§‹åŒ–å‚æ•°
        self.ocr = PaddleOCR(
            use_doc_orientation_classify=False,
            use_doc_unwarping=False,
            use_textline_orientation=False,
            lang="en",  # ä½¿ç”¨è‹±æ–‡æ¨¡å‹
            # device="gpu"  # å¦‚æœæœ‰GPUå¯ä»¥å¯ç”¨
        )

        # è¯„åˆ†æƒé‡é…ç½®
        self.weights = {
            'grammar': 0.3,
            'vocabulary': 0.2,
            'structure': 0.2,
            'content': 0.3
        }

        # è¯æ±‡åº“
        self.advanced_vocab = {
            'excellent', 'outstanding', 'remarkable', 'significant',
            'consequently', 'furthermore', 'moreover', 'nevertheless',
            'perspective', 'dilemma', 'phenomenon', 'contemporary'
        }

    def extract_text_from_image(self, image_path: str) -> str:
        """
        ä½¿ç”¨æ–°ç‰ˆPaddleOCR APIä»å›¾ç‰‡ä¸­æå–æ–‡æœ¬ - ä¿®å¤ç‰ˆæœ¬
        """
        try:
            # ä½¿ç”¨æ–°ç‰ˆpredictæ–¹æ³•
            result = self.ocr.predict(image_path)
            full_text = []

            # å¤„ç†ç»“æœ - ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å±æ€§å
            for res in result:
                # ä»OCRResultå¯¹è±¡ä¸­æå–æ–‡æœ¬ï¼Œä½¿ç”¨rec_textsè€Œä¸æ˜¯txt
                if hasattr(res, 'rec_texts') and res.rec_texts:
                    for text in res.rec_texts:
                        if text and text.strip():  # åªä¿ç•™éç©ºæ–‡æœ¬
                            full_text.append(text.strip())
                else:
                    # å¤‡ç”¨æ–¹æ³•ï¼šå°è¯•ä»å­—å…¸ä¸­è·å–
                    if isinstance(res, dict) and 'rec_texts' in res:
                        for text in res['rec_texts']:
                            if text and text.strip():
                                full_text.append(text.strip())

            return ' '.join(full_text) if full_text else ""

        except Exception as e:
            print(f"OCRè¯†åˆ«é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return ""

    def debug_ocr_structure(self, image_path: str):
        """
        è°ƒè¯•å‡½æ•°ï¼šæ‰“å°OCRç»“æœçš„ç»“æ„
        """
        try:
            result = self.ocr.predict(image_path)
            print("OCRç»“æœç»“æ„è°ƒè¯•:")
            print(f"ç»“æœç±»å‹: {type(result)}")

            for i, res in enumerate(result):
                print(f"\n--- ç¬¬{i + 1}ä¸ªç»“æœ ---")
                print(f"ç»“æœç±»å‹: {type(res)}")
                print(f"æ‰€æœ‰å±æ€§: {dir(res)}")

                # æ£€æŸ¥å¸¸è§å±æ€§
                for attr in ['rec_texts', 'txt', 'text', 'boxes', 'scores']:
                    if hasattr(res, attr):
                        value = getattr(res, attr)
                        print(f"{attr}: {type(value)} - {value}")

                # å¦‚æœæ˜¯å­—å…¸ç±»å‹
                if isinstance(res, dict):
                    print("å­—å…¸é”®:", res.keys())

            return result
        except Exception as e:
            print(f"è°ƒè¯•å¤±è´¥: {e}")
            return None

    def extract_text_robust(self, image_path: str) -> str:
        """
        æ›´å¥å£®çš„æ–‡æœ¬æå–æ–¹æ³•
        """
        try:
            result = self.ocr.predict(image_path)
            full_text = []

            for res in result:
                # æ–¹æ³•1: å°è¯•rec_textså±æ€§
                if hasattr(res, 'rec_texts') and res.rec_texts:
                    full_text.extend([t.strip() for t in res.rec_texts if t and t.strip()])

                # æ–¹æ³•2: å°è¯•ç›´æ¥è®¿é—®æ–‡æœ¬æ•°æ®
                elif hasattr(res, '__dict__'):
                    res_dict = res.__dict__
                    if 'rec_texts' in res_dict:
                        full_text.extend([t.strip() for t in res_dict['rec_texts'] if t and t.strip()])

                # æ–¹æ³•3: å¦‚æœæ˜¯å­—å…¸
                elif isinstance(res, dict) and 'rec_texts' in res:
                    full_text.extend([t.strip() for t in res['rec_texts'] if t and t.strip()])

            return ' '.join(full_text) if full_text else ""

        except Exception as e:
            print(f"æ–‡æœ¬æå–å¤±è´¥: {e}")
            return ""

    def preprocess_text(self, text: str) -> str:
        """æ–‡æœ¬é¢„å¤„ç†"""
        if not text:
            return ""
        text = re.sub(r'\s+', ' ', text)
        text = self.correct_common_errors(text)
        return text.strip()

    def correct_common_errors(self, text: str) -> str:
        """çº æ­£å¸¸è§OCRè¯†åˆ«é”™è¯¯"""
        corrections = {
            'rn': 'm', 'cl': 'd', 'vv': 'w',
            'I O': '10', 'l O': '10', '|': 'I',
            '0': 'O', '1': 'I', 'acaderic': 'academic'  # ä¿®æ­£ä½ æ—¥å¿—ä¸­çš„é”™è¯¯
        }
        for wrong, correct in corrections.items():
            text = text.replace(wrong, correct)
        return text

    def analyze_grammar(self, text: str) -> Dict:
        """è¯­æ³•åˆ†æ"""
        if not text:
            return {'score': 0, 'total_sentences': 0, 'avg_sentence_length': 0, 'errors': {}}

        sentences = re.split(r'[.!?]', text)
        sentences = [s.strip() for s in sentences if s.strip()]

        total_sentences = len(sentences)
        words = text.split()
        avg_sentence_length = len(words) / max(total_sentences, 1)

        errors = {
            'capitalization': len(re.findall(r'[a-z][.!?]\s+[a-z]', text)),
            'double_spaces': len(re.findall(r'  ', text)),
            'subject_verb_agreement': self.check_subject_verb_agreement(text)
        }

        total_errors = sum(errors.values())
        grammar_score = max(0, 100 - total_errors * 2)

        return {
            'score': round(grammar_score, 2),
            'total_sentences': total_sentences,
            'avg_sentence_length': round(avg_sentence_length, 2),
            'errors': errors
        }

    def check_subject_verb_agreement(self, text: str) -> int:
        """æ£€æŸ¥ä¸»è°“ä¸€è‡´é”™è¯¯"""
        errors = 0
        patterns = [
            r'\b(he|she|it)\s+(do|have)\b',
            r'\b(I|you|we|they)\s+(does|has)\b'
        ]
        for pattern in patterns:
            errors += len(re.findall(pattern, text.lower()))
        return errors

    def analyze_vocabulary(self, text: str) -> Dict:
        """è¯æ±‡åˆ†æ"""
        if not text:
            return {'score': 0, 'total_words': 0, 'unique_words': 0, 'lexical_diversity': 0}

        words = re.findall(r'\b[a-zA-Z]+\b', text.lower())
        total_words = len(words)
        if total_words == 0:
            return {'score': 0, 'total_words': 0, 'unique_words': 0, 'lexical_diversity': 0}

        unique_words = len(set(words))
        lexical_diversity = unique_words / total_words

        advanced_words_used = [word for word in words if word in self.advanced_vocab]
        advanced_ratio = len(advanced_words_used) / total_words

        vocabulary_score = min(100, (lexical_diversity * 60 + advanced_ratio * 40) * 100)

        return {
            'score': round(vocabulary_score, 2),
            'total_words': total_words,
            'unique_words': unique_words,
            'lexical_diversity': round(lexical_diversity, 3),
            'advanced_words_used': advanced_words_used
        }

    def analyze_structure(self, text: str) -> Dict:
        """ç»“æ„åˆ†æ"""
        if not text:
            return {'score': 0, 'sentences_count': 0, 'transitions_used': []}

        sentences = re.split(r'[.!?]', text)
        sentences = [s.strip() for s in sentences if s.strip()]

        transition_words = [
            'first', 'second', 'finally', 'however', 'therefore',
            'moreover', 'furthermore', 'consequently', 'in conclusion'
        ]

        transitions_used = []
        for word in transition_words:
            if word in text.lower():
                transitions_used.append(word)

        structure_score = min(100, len(sentences) * 3 + len(transitions_used) * 5)

        return {
            'score': round(structure_score, 2),
            'sentences_count': len(sentences),
            'transitions_used': transitions_used
        }

    def analyze_content(self, text: str) -> Dict:
        """å†…å®¹è´¨é‡åˆ†æ"""
        if not text:
            return {'score': 0, 'word_count': 0, 'feedback': 'æœªè¯†åˆ«åˆ°æ–‡æœ¬å†…å®¹'}

        words = text.split()
        word_count = len(words)

        if word_count < 50:
            content_score = 50
        elif word_count < 100:
            content_score = 60
        elif word_count < 200:
            content_score = 75
        elif word_count < 300:
            content_score = 85
        else:
            content_score = 90

        return {
            'score': round(content_score, 2),
            'word_count': word_count,
            'feedback': self.generate_content_feedback(word_count)
        }

    def generate_content_feedback(self, word_count: int) -> str:
        if word_count < 50:
            return "æ–‡ç« è¿‡çŸ­ï¼Œå»ºè®®å¤§å¹…æ‰©å±•å†…å®¹ã€‚"
        elif word_count < 100:
            return "æ–‡ç« è¾ƒçŸ­ï¼Œå»ºè®®æ‰©å±•å†…å®¹ã€‚"
        elif word_count < 200:
            return "æ–‡ç« é•¿åº¦é€‚ä¸­ã€‚"
        else:
            return "æ–‡ç« å†…å®¹ä¸°å¯Œã€‚"

    def calculate_overall_score(self, scores: Dict) -> float:
        total = 0
        for category, score_info in scores.items():
            if category in self.weights:
                total += score_info['score'] * self.weights[category]
        return round(total, 2)

    def grade_essay(self, image_path: str) -> Dict:
        """ä¸»è¯„åˆ†å‡½æ•°"""
        if not os.path.exists(image_path):
            return {"error": f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}"}

        print("æ­£åœ¨è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡æœ¬...")

        # å…ˆè°ƒè¯•OCRç»“æ„
        self.debug_ocr_structure(image_path)

        # ä½¿ç”¨å¥å£®çš„æ–‡æœ¬æå–æ–¹æ³•
        raw_text = self.extract_text_robust(image_path)

        if not raw_text:
            # å¤‡ç”¨æ–¹æ³•ï¼šå°è¯•ç›´æ¥æå–
            raw_text = self.extract_text_from_image(image_path)

        if not raw_text:
            return {"error": "æ— æ³•ä»å›¾ç‰‡ä¸­è¯†åˆ«å‡ºæ–‡æœ¬"}

        print("è¯†åˆ«åˆ°çš„æ–‡æœ¬:")
        print(raw_text)
        print("\n" + "=" * 50)

        processed_text = self.preprocess_text(raw_text)

        grammar_analysis = self.analyze_grammar(processed_text)
        vocabulary_analysis = self.analyze_vocabulary(processed_text)
        structure_analysis = self.analyze_structure(processed_text)
        content_analysis = self.analyze_content(processed_text)

        analysis_results = {
            'grammar': grammar_analysis,
            'vocabulary': vocabulary_analysis,
            'structure': structure_analysis,
            'content': content_analysis
        }

        overall_score = self.calculate_overall_score(analysis_results)

        return {
            'original_text': raw_text,
            'processed_text': processed_text,
            'overall_score': overall_score,
            'detailed_analysis': analysis_results,
            'word_count': len(processed_text.split())
        }

    def save_ocr_result(self, image_path: str, output_dir: str = "output"):
        """ä¿å­˜OCRçš„å¯è§†åŒ–ç»“æœå’ŒJSONæ•°æ®"""
        try:
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)

            result = self.ocr.predict(image_path)

            for i, res in enumerate(result):
                # ä¿å­˜å¯è§†åŒ–å›¾ç‰‡
                res.save_to_img(output_dir)
                # ä¿å­˜JSONæ•°æ®
                res.save_to_json(output_dir)
                # æ‰“å°ç»“æœ
                res.print()

            print(f"OCRç»“æœå·²ä¿å­˜åˆ° {output_dir} ç›®å½•")

        except Exception as e:
            print(f"ä¿å­˜OCRç»“æœå¤±è´¥: {e}")

    def print_results(self, results: Dict):
        """æ ¼å¼åŒ–è¾“å‡ºç»“æœ"""
        if 'error' in results:
            print(f"é”™è¯¯: {results['error']}")
            return

        print("\n" + "=" * 60)
        print("           è‹±è¯­ä½œæ–‡è¯„åˆ†ç»“æœ")
        print("=" * 60)

        print(f"\nğŸ“ è¯†åˆ«åˆ°çš„æ–‡æœ¬:")
        print(f"   {results['processed_text']}")

        print(f"\nğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
        print(f"   æ€»å­—æ•°: {results['word_count']}")

        print(f"\nğŸ¯ ç»¼åˆè¯„åˆ†: {results['overall_score']}/100")

        print(f"\nğŸ“– è¯¦ç»†åˆ†æ:")
        analysis = results['detailed_analysis']

        for category, details in analysis.items():
            print(f"\n  {category.upper()}åˆ†æ:")
            for key, value in details.items():
                if key != 'score' and value:
                    if isinstance(value, list):
                        if value:
                            print(f"    {key}: {', '.join(value)}")
                    else:
                        print(f"    {key}: {value}")
            print(f"    è¯„åˆ†: {details['score']}/100")

        print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        self.generate_improvement_suggestions(analysis)

    def generate_improvement_suggestions(self, analysis: Dict):
        suggestions = []
        if analysis['grammar']['score'] < 80:
            suggestions.append("â€¢ æ³¨æ„è¯­æ³•å‡†ç¡®æ€§")
        if analysis['vocabulary']['score'] < 70:
            suggestions.append("â€¢ å°è¯•ä½¿ç”¨æ›´å¤šé«˜çº§è¯æ±‡")
        if analysis['structure']['score'] < 75:
            suggestions.append("â€¢ åŠ å¼ºæ–‡ç« ç»“æ„ï¼Œä½¿ç”¨è¿‡æ¸¡è¯")
        if analysis['content']['score'] < 80:
            suggestions.append("â€¢ ä¸°å¯Œæ–‡ç« å†…å®¹")

        if not suggestions:
            suggestions.append("â€¢ ç»§ç»­ä¿æŒï¼Œæ–‡ç« è´¨é‡å¾ˆå¥½ï¼")

        for suggestion in suggestions:
            print(suggestion)


def create_sample_image():
    """åˆ›å»ºä¸€ä¸ªç¤ºä¾‹å›¾ç‰‡ç”¨äºæµ‹è¯•"""
    try:
        # åˆ›å»ºä¸€ä¸ªç©ºç™½å›¾ç‰‡
        img = np.ones((500, 700, 3), dtype=np.uint8) * 255  # ç™½è‰²èƒŒæ™¯

        # æ·»åŠ æ–‡æœ¬
        text_lines = [
            "The Importance of Learning English",
            "",
            "English is an international language that",
            "is widely used around the world. Learning",
            "English can open up many opportunities for",
            "people. It helps in communication with",
            "people from different countries and cultures.",
            "",
            "Moreover, English is the language of",
            "science and technology. Many books and",
            "research papers are written in English.",
            "Therefore, learning English is essential",
            "for academic success.",
            "",
            "In conclusion, English is very important",
            "in today's globalized world."
        ]

        # è®¾ç½®å­—ä½“
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        font_color = (0, 0, 0)  # é»‘è‰²
        thickness = 1

        # åœ¨å›¾ç‰‡ä¸Šå†™æ–‡æœ¬
        y = 40
        for line in text_lines:
            if line:  # éç©ºè¡Œ
                cv2.putText(img, line, (30, y), font, font_scale, font_color, thickness)
            y += 35

        # ä¿å­˜å›¾ç‰‡
        cv2.imwrite('sample_essay.jpg', img)
        print("âœ… å·²åˆ›å»ºç¤ºä¾‹å›¾ç‰‡: sample_essay.jpg")
        return 'sample_essay.jpg'

    except Exception as e:
        print(f"åˆ›å»ºç¤ºä¾‹å›¾ç‰‡å¤±è´¥: {e}")
        return None


def main():
    print("=" * 60)
    print("        è‹±è¯­ä½œæ–‡è‡ªåŠ¨è¯„åˆ†ç³»ç»Ÿ (ä¿®å¤ç‰ˆ)")
    print("=" * 60)

    # åˆå§‹åŒ–è¯„åˆ†å™¨
    print("åˆå§‹åŒ–è¯„åˆ†ç³»ç»Ÿ...")
    grader = EnglishEssayGrader()

    # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•å›¾ç‰‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»º
    image_path = "sample_essay.jpg"
    if not os.path.exists(image_path):
        print("æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡ï¼Œæ­£åœ¨åˆ›å»ºç¤ºä¾‹å›¾ç‰‡...")
        image_path = create_sample_image()
        if not image_path:
            custom_path = input("è¯·æ‰‹åŠ¨è¾“å…¥ä½œæ–‡å›¾ç‰‡è·¯å¾„: ")
            image_path = custom_path.strip() if custom_path.strip() else "sample_essay.jpg"

    if not os.path.exists(image_path):
        print(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return

    print(f"ä½¿ç”¨å›¾ç‰‡: {image_path}")

    try:
        # ä¿å­˜OCRçš„å¯è§†åŒ–ç»“æœ
        print("æ­£åœ¨ç”ŸæˆOCRå¯è§†åŒ–ç»“æœ...")
        grader.save_ocr_result(image_path, "ocr_output")

        # è¿›è¡Œä½œæ–‡è¯„åˆ†
        results = grader.grade_essay(image_path)
        grader.print_results(results)

        # ä¿å­˜è¯„åˆ†ç»“æœ
        with open('essay_score_result.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… è¯„åˆ†ç»“æœå·²ä¿å­˜åˆ° essay_score_result.json")

    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()